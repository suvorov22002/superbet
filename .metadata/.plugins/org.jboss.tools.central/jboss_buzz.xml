<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Debugging in GDB: Create custom stack winders</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/19/debugging-gdb-create-custom-stack-winders" /><author><name>Andrew Burgess</name></author><id>1b158985-49f8-4ef2-8f7a-afa95cad693f</id><updated>2023-06-19T07:00:00Z</updated><published>2023-06-19T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will walk through the process of creating a custom stack unwinder for the GNU Project Debugger (GDB) using GDB's &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; API. We'll first explore when writing such an unwinder might be necessary, then create a small example application that demonstrates a need for a custom unwinder before finally writing a custom unwinder for our application inside the debugger.&lt;/p&gt; &lt;p&gt;By the end of this tutorial, you'll be able to use our custom stack unwinder to allow GDB to create a full backtrace for our application.&lt;/p&gt; &lt;h2&gt;What is an unwinder?&lt;/h2&gt; &lt;p&gt;An unwinder is how GDB figures out the call stack of an inferior, for example, GDB's &lt;code&gt;backtrace&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;Breakpoint 1, woof () at stack.c:4 4 return 0; (gdb) backtrace #0 woof () at stack.c:4 #1 0x000000000040111f in bar () at stack.c:10 #2 0x000000000040112f in foo () at stack.c:16 #3 0x000000000040113f in main () at stack.c:22 (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Figuring out frame #0 is easy; the current program counter (&lt;code&gt;$pc&lt;/code&gt;) value tells GDB which function the inferior is currently in. But to figure out the other frames, GDB needs to read information from the inferior's registers and memory. The unwinder is the component of GDB that performs this task.&lt;/p&gt; &lt;p&gt;Having an understanding of the inferior's frames isn't just used for displaying the backtrace, though; commands like &lt;code&gt;next&lt;/code&gt; and &lt;code&gt;finish&lt;/code&gt; also need an accurate understanding of the stack frames in order to function properly.&lt;/p&gt; &lt;p&gt;Any time GDB needs information about a frame beyond #0, an unwinder will have been used.&lt;/p&gt; &lt;h2&gt;What is a custom unwinder?&lt;/h2&gt; &lt;p&gt;GDB already has multiple built-in unwinders for all the major architectures GDB supports. By far, the most common unwinder will be the DWARF unwinder, which reads the DWARF debug information and uses it to unwind the stack for GDB.&lt;/p&gt; &lt;p&gt;But not all functions are compiled with debug information. When GDB finds a function without DWARF debug information, it falls back to a built-in prologue analysis unwinder.&lt;/p&gt; &lt;p&gt;The prologue analysis unwinder disassembles the instructions at the start of a function and uses this information, combined with an understanding of the architecture's ABI, to provide unwind information. For many functions, the prologue analysis unwinder will do a reasonable job. Still, there's a limit to how smart the prologue analysis unwinder can be, and GDB can never expect to handle every function this way.&lt;/p&gt; &lt;p&gt;And this is where the Python unwinder API comes in. Using this API, it is possible to write Python code that will be loaded into GDB. This code can then "claim" frames for which GDB is otherwise unable to unwind correctly, and the Python code can instead be used to provide the unwind information to GDB.&lt;/p&gt; &lt;h2&gt;Building an example use case&lt;/h2&gt; &lt;p&gt;In most well-written applications, very few functions will need the support of a custom unwinder. The sort of functions that GDB will struggle with are those that do unexpected things with the underlying machine state; for example, functions that manipulate the stack in unexpected ways are likely to confuse GDB.&lt;/p&gt; &lt;p&gt;The example application we're going to write does just that: it allocates a second stack and uses a small assembler function to switch to, and run a function on, the new stack.&lt;/p&gt; &lt;p&gt;GDB will have no problem unwinding the standard C frames, but the assembler function, which changes the stack, is going to confuse GDB, and initially, we will be unable to obtain a &lt;code&gt;backtrace&lt;/code&gt; through this function.&lt;/p&gt; &lt;p&gt;Of course, writing in assembly language means this application will only work for one architecture, in this case, x86-64, and the unwinder we eventually write will also be tied to this one architecture. This is perfectly normal; unwinders are dealing with machine registers, so it is expected that an unwinder will only apply to a single architecture.&lt;/p&gt; &lt;p&gt;The demonstration application is split into two files, first, we have &lt;code&gt;demo.c&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cpp"&gt;#include &lt;stdio.h&gt; #include &lt;sys/mman.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; /* This function is in our assembly file. */ extern void run_on_new_stack (void *stack, void (*) (void)); /* Return pointer to the top of a new stack. */ static void * allocate_new_stack (void) { int pagesz = getpagesize (); void *ptr = mmap (NULL, pagesz, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); if (ptr == MAP_FAILED) abort (); return ptr + pagesz; } /* A function to run on the alternative stack. */ static void func (void) { printf ("Hello world\n"); } /* Allocate a new stack. Run a function on the new stack. */ int main (void) { void *new_stack = allocate_new_stack (); run_on_new_stack (new_stack, func); return 0; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then we have &lt;code&gt;runon.S&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; .global run_on_new_stack run_on_new_stack: /* Incoming arguments: %rdi - top of new stack pointer, %rsi - function to call. Store previous %rbp and %rsp to the new stack. Set %rbp and $rsp to point to the new stack. Call the function in %rsi. */ mov %rbp, -8(%rdi) mov %rsp, -16(%rdi) add $-16, %rdi mov %rdi, %rbp mov %rdi, %rsp callq *%rsi movq 0(%rbp), %rsp movq 8(%rbp), %rbp ret .size run_on_new_stack, . - run_on_new_stack .type run_on_new_stack, @function &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finally, compile the application like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;gcc -g3 -O0 -Wall -Werror -o demo demo.c runon.S&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now let's see how GDB handles stack unwinding without any additional support. For this, I'm using GDB 13.1:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) backtrace #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00007fffffffad68 in ?? () #3 0x00007fffffffad80 in ?? () #4 0x0000000000000000 in ?? () (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see, GDB can unwind from &lt;code&gt;func&lt;/code&gt; just fine; after all, that is a "normal" function compiled with debug information. But GDB is unable to figure out how to unwind from &lt;code&gt;run_on_new_stack&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;What our application is actually doing&lt;/h3&gt; &lt;p&gt;Before we can write a custom unwinder in Python, we need to make sure we fully understand what the demonstration application is actually doing.&lt;/p&gt; &lt;p&gt;We have three frames: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;run_on_new_stack&lt;/code&gt;, and &lt;code&gt;func&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In &lt;code&gt;main&lt;/code&gt;, just before we call &lt;code&gt;run_on_new_stack&lt;/code&gt;, the application’s stack looks like Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_01_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_01_0.png?itok=qh8NGQuG" width="532" height="397" alt="Stack in main, just before run_on_new_stack is called." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: Stack in main, just before run_on_new_stack is called.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The register &lt;code&gt;%rbp&lt;/code&gt;, sometimes known as the frame pointer, points to the top of the frame for &lt;code&gt;main&lt;/code&gt;, while &lt;code&gt;%rsp&lt;/code&gt;, otherwise known as the stack pointer, points to the last valid address of the frame for &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When we call from &lt;code&gt;main&lt;/code&gt; to &lt;code&gt;run_on_new_stack&lt;/code&gt;, the return address within &lt;code&gt;main&lt;/code&gt; is pushed onto the stack and &lt;code&gt;%rsp&lt;/code&gt; is updated. The stack now looks like Figure 2.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_02_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_02_0.png?itok=VAH8dv9U" width="532" height="454" alt="State of the stack upon entry to run_on_new_stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: State of the stack upon entry to run_on_new_stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;In &lt;code&gt;main&lt;/code&gt;, we also allocated a new stack, and this was passed through as the first function argument to &lt;code&gt;run_on_new_stack&lt;/code&gt;. As such, register &lt;code&gt;%rdi&lt;/code&gt; points at an address just above the new stack, like this (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_03_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_03_0.png?itok=MiI5PIb6" width="310" height="397" alt="Visualisation of the new, empty stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: Visualisation of the new, empty stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Within &lt;code&gt;run_on_new_stack&lt;/code&gt; we switch over to the new stack. The return address within &lt;code&gt;main&lt;/code&gt; is left on the original stack, and the pointers (&lt;code&gt;%rbp&lt;/code&gt; and &lt;code&gt;%rsp&lt;/code&gt;) to the original stack are backed up on the new stack, and then updated to point at the new stack. We then call &lt;code&gt;func&lt;/code&gt;, which will push the return address within &lt;code&gt;run_on_new_stack&lt;/code&gt; onto the new stack. Once we are in &lt;code&gt;func&lt;/code&gt;, the state of the two stacks is now as shown in Figures 4 and 5.&lt;/p&gt; &lt;table border="0" cellpadding="1" cellspacing="1"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_04_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_04_0.png?itok=gstn156K" width="443" height="397" alt="Layout of the original stack once run_on_new_stack has switched to the new stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Layout of the original stack once run_on_new_stack has switched to the new stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/td&gt; &lt;td&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stack_05_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stack_05_0.png?itok=lK6M13ca" width="532" height="454" alt="Layout of new stack." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Layout of new stack.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;When unwinding, GDB doesn't understand how to use the information on the new stack to find the original stack, and so the &lt;code&gt;backtrace&lt;/code&gt; is incomplete. This is the problem that our custom unwinder will solve for us.&lt;/p&gt; &lt;h3&gt;Starting our custom unwinder&lt;/h3&gt; &lt;p&gt;The custom unwinder will be written as a Python script in the file &lt;code&gt;runon-unwind.py&lt;/code&gt;, which we can then source in GDB to provide the extra functionality.&lt;/p&gt; &lt;p&gt;In GDB's Python API, an unwinder is an object that implements the &lt;code&gt;__call__&lt;/code&gt; method. GDB will call each unwinder object for every frame; the unwinder should return &lt;code&gt;None&lt;/code&gt; if the unwinder doesn't handle the frame or return a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object if the unwinder wishes to take responsibility for the frame.&lt;/p&gt; &lt;p&gt;Let's start by writing an empty unwinder that doesn't claim any frames:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last line of this file is responsible for registering the new unwinder with GDB. The first argument &lt;code&gt;None&lt;/code&gt; tells GDB to register this unwinder in the global scope, but it is also possible to register an unwinder for a specific object file or a specific program space. We'll not cover these cases in this tutorial, but the &lt;a href="https://sourceware.org/gdb/current/onlinedocs/gdb.html/Unwinding-Frames-in-Python.html"&gt;GDB documentation&lt;/a&gt; has more details.&lt;/p&gt; &lt;p&gt;The second argument to &lt;code&gt;register_unwinder&lt;/code&gt; is our new unwinder object. We'll discuss this more below.&lt;/p&gt; &lt;p&gt;The final argument &lt;code&gt;replace=True&lt;/code&gt; indicates that this new unwinder should replace any existing unwinder with the same name. This is useful when developing the unwinder as we can adjust our script and re-source it from GDB; the updated unwinder will then replace the existing one.&lt;/p&gt; &lt;p&gt;In our unwinder object &lt;code&gt;runto_unwinder&lt;/code&gt;, the constructor just calls the parent constructor and passes in a name for our unwinder. The name can be used within GDB to disable and enable the unwinder using the &lt;code&gt;disable unwinder&lt;/code&gt; and &lt;code&gt;enable unwinder&lt;/code&gt; commands, respectively. There is also &lt;code&gt;info unwinder&lt;/code&gt; which lists all the registered Python unwinders.&lt;/p&gt; &lt;p&gt;Our unwinder object also implements the required &lt;code&gt;__call__&lt;/code&gt; method. This method is passed a &lt;code&gt;gdb.PendingFrame&lt;/code&gt; object in &lt;code&gt;pending_frame&lt;/code&gt;. This pending frame describes the frame that is searching for an unwinder. We must examine this object and decide whether this unwinder applies to this pending frame. By returning &lt;code&gt;None&lt;/code&gt;, our unwinder is currently telling GDB that we don't wish to claim &lt;code&gt;pending_frame&lt;/code&gt;, our unwinder as it currently stands will not claim any frames, but we can start to address that next.&lt;/p&gt; &lt;h3&gt;Identifying frames to claim&lt;/h3&gt; &lt;p&gt;The first task our new unwinder needs to do is to decide which frame, or frames, should be claimed and which should not be claimed. Any frames not claimed by our unwinder will be offered to any other registered unwinders and will then be offered to GDB's built-in unwinders.&lt;/p&gt; &lt;p&gt;The easiest way to decide if we should claim a frame or not is to compare the program-counter address within the frame to the address range of the function we're claiming for—in this case, &lt;code&gt;run_on_new_stack&lt;/code&gt;. We can easily find the program-counter address for the frame by reading the &lt;code&gt;$pc&lt;/code&gt; register. This is done using the &lt;code&gt;read_register&lt;/code&gt; method of the &lt;code&gt;gdb.PendingFrame&lt;/code&gt; class.&lt;/p&gt; &lt;p&gt;Having read &lt;code&gt;$pc&lt;/code&gt;, we need an address range to compare against. For that, we will make use of GDB's disassembler. We will disassemble &lt;code&gt;run_on_new_stack&lt;/code&gt; and extract the address of each instruction. We can then use the first and last addresses as the lower and upper bounds that our unwinder should claim.&lt;/p&gt; &lt;p&gt;Update &lt;code&gt;runon-unwinder.py&lt;/code&gt; like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None print(f"Found a frame we can handle at: {pc}") return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The new &lt;code&gt;analyze&lt;/code&gt; function disassembles &lt;code&gt;run_on_new_stack&lt;/code&gt; and stores the address of each instruction in the global &lt;code&gt;_unwind_analysis&lt;/code&gt; list.&lt;/p&gt; &lt;p&gt;In &lt;code&gt;runto_unwinder.__call__&lt;/code&gt; we initialize &lt;code&gt;_unwind_analysis&lt;/code&gt; by calling &lt;code&gt;analyze&lt;/code&gt; once. We read &lt;code&gt;$pc&lt;/code&gt; by calling &lt;code&gt;pending_frame.read_register&lt;/code&gt;, and then we compare &lt;code&gt;pc&lt;/code&gt; to the first and last addresses in &lt;code&gt;_unwind_analysis&lt;/code&gt;. If the frame's program-counter is outside of the accepted range, then we return &lt;code&gt;None&lt;/code&gt;; this indicates to GDB that we don't wish to claim this frame.&lt;/p&gt; &lt;p&gt;If the frame's program-counter is within the range of &lt;code&gt;run_on_new_stack&lt;/code&gt;, then we print a message, and, for now, also return &lt;code&gt;None&lt;/code&gt;—don't worry, though, we'll soon be doing more than returning &lt;code&gt;None&lt;/code&gt; here, but right now, let's test our code.&lt;/p&gt; &lt;p&gt;Using the same demonstration application as before, here's an example GDB session:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) source runto-unwind.py (gdb) backtrace Found a frame we can handle at: 0x4011fb &lt;run_on_new_stack+20&gt; #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00007fffffffad38 in ?? () #3 0x00007fffffffad50 in ?? () #4 0x0000000000000000 in ?? () (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notice the line: &lt;code&gt;Found a frame we can handle at: 0x4011fb &lt;run_on_new_stack+20&gt;&lt;/code&gt;. Don't worry if the addresses you see are different; what's important is that the message is printed—and printed just once. This indicates that our unwinder has identified a single frame it wishes to claim. The address from that line, &lt;code&gt;0x4011fb&lt;/code&gt;, matches the address from frame #1, the &lt;code&gt;run_on_new_stack&lt;/code&gt; frame; this shows that the correct frame was claimed.&lt;/p&gt; &lt;h3&gt;A detour into frame-ids&lt;/h3&gt; &lt;p&gt;The next step is to update the &lt;code&gt;__call__&lt;/code&gt; method to return a value that indicates the frame has been claimed by this unwinder. However, in order to claim the frame, we must provide a frame-id for the frame.&lt;/p&gt; &lt;p&gt;A frame-id is a unique identifier generated by the unwinder that must be unique for each stack frame but the same for every address within a particular invocation of a function.&lt;/p&gt; &lt;p&gt;Imagine the case where GDB is stepping through a function. After each step, GDB needs to recognize if it is still in the same frame or not. After each step, the unwinder will be used to identify the frame and generate the frame-id again. So long as the generated frame-id is always the same, GDB will understand it is still in the same frame.&lt;/p&gt; &lt;p&gt;Within GDB, frame-ids are a tuple of stack-pointer and code-pointer addresses. Often unwinders use the stack address at entry to the function (typically called the frame base address), and the program address for the function's first instruction.&lt;/p&gt; &lt;p&gt;Within GDB's Python API, a frame-id is represented by any object that has the &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt; attributes. These attributes should contain &lt;code&gt;gdb.Value&lt;/code&gt; objects representing their respective addresses.&lt;/p&gt; &lt;h3&gt;Creating a frame-ID and UnwindInfo object&lt;/h3&gt; &lt;p&gt;Now that we know about frame-ids, let's dive in and update our unwinder. We'll discuss these changes afterward. Update &lt;code&gt;runto-unwind.py&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class FrameID: def __init__(self, sp, pc): self.sp = sp self.pc = pc class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None # Create a frame id that will remain consistent throughout # the frame, no matter what $pc we stop at. We use the $sp # value for the previous frame (this was our $sp on frame # entry), and we use the $pc for the start of the function. # # For the first four and last two instructions, the previous # $sp value can be found in the %rsp register. # # For the fifth and sixth instructions we need to fetch the # previous $sp value from the original stack. rsp = pending_frame.read_register("rsp") if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp) func_start = gdb.Value(_unwind_analysis[0]) frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id) print(f"Found a frame we can handle at: {pc}") return None gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Currently, GDB doesn't include any helper classes that can be used to represent a frame-id, so we need to define our own – &lt;code&gt;FrameID&lt;/code&gt;. The only requirements are that this class has the &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt; attributes.&lt;/p&gt; &lt;p&gt;Within the &lt;code&gt;__call__&lt;/code&gt; method we use the first address of &lt;code&gt;run_on_new_stack&lt;/code&gt; as the program-counter value for the frame-id. This is done with this line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; func_start = gdb.Value(_unwind_analysis[0])&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the stack-pointer address of the frame-id, we need to be smarter. When we first enter &lt;code&gt;run_on_new_stack&lt;/code&gt;, the previous stack-pointer value is still present in &lt;code&gt;%rsp&lt;/code&gt;, but within &lt;code&gt;run_on_new_stack&lt;/code&gt;, the &lt;code&gt;%rsp&lt;/code&gt; register is stored to the new stack and a new value loaded into &lt;code&gt;%rsp&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To handle these two cases, we use the following block of code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We choose between the two possible paths based on the current location within the function. The addresses &lt;code&gt;_unwind_analysis[5]&lt;/code&gt; and &lt;code&gt;_unwind_analysis[6]&lt;/code&gt; were chosen by reviewing the instruction disassembly for &lt;code&gt;run_on_new_stack&lt;/code&gt;. A good exercise would be to disassemble the function and convince yourself that the above choices are correct.&lt;/p&gt; &lt;p&gt;We can now create an instance of our &lt;code&gt;FrameID&lt;/code&gt; class and use this instance to create a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object with these lines:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; class is the last piece of the unwinder process. We will store unwound register values into our &lt;code&gt;unwind_info&lt;/code&gt; object and return this to GDB in order to claim this frame. However, we're not there just yet—for now, we're still printing a debug message and returning &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Adding unwound register values&lt;/h3&gt; &lt;p&gt;Having decided to claim this frame, and having created a &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object, we need to store some unwound register values in our new &lt;code&gt;unwind_info&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;The unwound value of a register is the value a register had in the previous frame.&lt;/p&gt; &lt;p&gt;Locating the previous register values will involve understanding the assembler code for the function being unwound. You don't need to provide previous values for every register; in some cases, the previous value of a register will not be available at all, in which case nothing can be done.&lt;/p&gt; &lt;p&gt;To keep the complexity of this example down, we are only going to provide previous values for 3 registers, the program counter, &lt;code&gt;%rsp&lt;/code&gt;, and &lt;code&gt;%rbp&lt;/code&gt;. These registers are enough to allow GDB to build a complete backtrace on x86-64. Once you've seen how these registers are supported, extending the example to support other registers as needed should be easy enough.&lt;/p&gt; &lt;p&gt;As before, let's just update &lt;code&gt;runon-unwind.py&lt;/code&gt;, and discuss the changes afterwards:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from gdb.unwinder import Unwinder _unwind_analysis = None def analyze(): global _unwind_analysis # Disassemble the run_on_new_stack function. disasm = gdb.execute("disassemble run_on_new_stack", False, True) # Discard the first and last lines, these don't contain # disassembled instructions, and are of no interest. disasm = disasm.splitlines()[1:-1] # Extract the address of each instruction, and store these # addresses into the global _unwind_analysis list. disasm = [int(l.lstrip().split()[0], 16) for l in disasm] _unwind_analysis = disasm class FrameID: def __init__(self, sp, pc): self.sp = sp self.pc = pc class runto_unwinder(Unwinder): def __init__(self): super().__init__("runto_unwinder") def __call__(self, pending_frame): # Analyze the function we're going to unwind. global _unwind_analysis if _unwind_analysis is None: analyze() # If this is not a frame we handle then return None. pc = pending_frame.read_register("pc") if pc &lt; _unwind_analysis[0] or pc &gt; _unwind_analysis[-1]: return None # Create a frame id that will remain consistent throughout the # frame, no matter what $pc we stop at. We use the $sp value # for the previous frame (this was our $sp on frame entry), # and we use the $pc for the start of the function. # # For the first four and last two instructions, the previous # $sp value can be found in the %rsp register. # # For the fifth and sixth instructions we need to fetch the # previous $sp value from the original stack. rsp = pending_frame.read_register("rsp") if pc &lt; _unwind_analysis[5] or pc &gt; _unwind_analysis[6]: frame_sp = rsp else: frame_sp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % rsp) func_start = gdb.Value(_unwind_analysis[0]) frame_id = FrameID(frame_sp, func_start) # Create the unwind_info cache object which holds our unwound # registers. unwind_info = pending_frame.create_unwind_info(frame_id) # Calculate the previous register values. Select the correct # previous value for $rbp based on where we are in the # function. if pc &lt; _unwind_analysis[4] or pc &gt; _unwind_analysis[7]: prev_rbp = pending_frame.read_register("rbp") else: prev_rbp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (rsp + 8)) # We use the previous $sp value in our frame-id, which is handy! prev_rsp = frame_sp # The previous $pc is always on the original (incoming) stack. prev_pc = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (prev_rsp)) # And store the previous values into our cache. unwind_info.add_saved_register("rsp", prev_rsp) unwind_info.add_saved_register("rbp", prev_rbp) unwind_info.add_saved_register("pc", prev_pc) # Return the cache for GDB to use. return unwind_info gdb.unwinder.register_unwinder(None, runto_unwinder(), replace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The most important part of this new version are the three calls to &lt;code&gt;unwind_info.add_saved_register&lt;/code&gt;; this is how we record the unwound register values. The first argument to these calls is the name of the register we are recording, and the second argument is the value that register had in the previous frame.&lt;/p&gt; &lt;p&gt;The three registers we record are &lt;code&gt;pc&lt;/code&gt;, &lt;code&gt;rsp&lt;/code&gt;, and &lt;code&gt;rbp&lt;/code&gt;. Figuring out the previous value for the first two registers is pretty easy. We already have the previous &lt;code&gt;rsp&lt;/code&gt; value, remember, this is what we used for our frame-id so that we can reuse that value here.&lt;/p&gt; &lt;p&gt;Recall from our earlier stack diagrams; the return address in &lt;code&gt;main&lt;/code&gt; was the last thing stored on the original stack, this is what the previous stack-pointer points at, so we can load the return address with this line:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; prev_pc = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (prev_rsp))&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And this just leaves the previous &lt;code&gt;rbp&lt;/code&gt; value. Just like we found the previous &lt;code&gt;rsp&lt;/code&gt; value earlier, the current instruction within &lt;code&gt;run_on_new_stack&lt;/code&gt; will determine the location of the previous &lt;code&gt;rbp&lt;/code&gt; value. Initially the previous value is in the &lt;code&gt;rbp&lt;/code&gt; register, but we store this previous value to the new stack before calling &lt;code&gt;func&lt;/code&gt;. And so, to find the correct previous value, we need to switch based on the program-counter value, which we do with these lines:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt; if pc &lt; _unwind_analysis[4] or pc &gt; _unwind_analysis[7]: prev_rbp = pending_frame.read_register("rbp") else: prev_rbp = gdb.parse_and_eval("*((unsigned long long *) 0x%x)" % (rsp + 8))&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The last update is to remove the debug message that we have been printing until now, and instead of returning &lt;code&gt;None&lt;/code&gt;, return our &lt;code&gt;gdb.UnwindInfo&lt;/code&gt; object &lt;code&gt;unwind_info&lt;/code&gt;. This tells GDB that our unwinder has claimed this frame. GDB will use the previous register values stored within &lt;code&gt;unwind_info&lt;/code&gt; when it needs to unwind through this frame.&lt;/p&gt; &lt;p&gt;So, for the last time, let's try our unwinder in GDB:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ gdb -q demo Reading symbols from demo... (gdb) break func Breakpoint 1 at 0x4011b1: file demo.c, line 25. (gdb) run Starting program: /tmp/demo Breakpoint 1, func () at demo.c:25 25 printf ("Hello world\n"); (gdb) source runon-unwind.py (gdb) backtrace #0 func () at demo.c:25 #1 0x00000000004011fb in run_on_new_stack () at runon.S:19 #2 0x00000000004011e0 in main () at demo.c:33 (gdb)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And success! We can now unwind through &lt;code&gt;run_on_new_stack&lt;/code&gt; back to &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Summary and conclusions&lt;/h3&gt; &lt;p&gt;Writing custom stack unwinders is not trivial; it requires a good understanding of the function being unwound and the architecture the unwinder is being written for. There is more to GDB's unwinder API than has been discussed in this brief introduction. The full details can all be found in the &lt;a href="https://sourceware.org/gdb/current/onlinedocs/gdb.html/Unwinding-Frames-in-Python.html"&gt;documentation&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/19/debugging-gdb-create-custom-stack-winders" title="Debugging in GDB: Create custom stack winders"&gt;Debugging in GDB: Create custom stack winders&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Andrew Burgess</dc:creator><dc:date>2023-06-19T07:00:00Z</dc:date></entry><entry><title type="html">Life in First Principles</title><link rel="alternate" href="http://www.ofbizian.com/2023/06/life-in-first-principles.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2023/06/life-in-first-principles.html</id><updated>2023-06-16T07:27:00Z</updated><content type="html">Let's express life through its finite ingredients. There are three resources in life that everything else depends on. Every time you waste any of them, they're gone forever. These are time, energy, and focus. TIME Time is the one variable that nobody has any control over. There are 24 hours in a day, 365 days in a year. Time offers the same equal consistency to everybody, but at different lengths. We are born, we live, and we die. All you can do is maximise the other variables in the time given to you, in a way meaningful to you. ENERGY Being alive is a prerequisite, but not sufficient to reach happiness. Given a lifetime, to maximise your purpose and happiness, depends on your energy levels. Energy is the ability to do things, physically or mentally. Having a body sufficiently healthy that will enable you to pursue your purpose. For some, this can be a physically strong body, having a good sleep, healthy diet, and regular exercise. For others, it can be sufficient to be able to get up from the bed and hold a pen. And for some even the ability to express your thoughts through a computer device (such as Stephen Hawking). Energy levels vary from person to person, but so are the energy needs. Energy is not a "have or have not" constant like life is, it is rather a variable that tends that changes every moment, and tends to go down with age. Energy is the multiplier that lets you get the best out of the time given to you. FOCUS Being lucky to be alive, and having sufficient energy, gives the optionality to spend your attention in many ways. Focus is about how we use our time and energy in a directed way. It is the ability to concentrate our attention in a direction that makes us happy, or spread and waste in the universe in a way benefiting others or nobody. Focus is the variable that we have most control over, and the variable that has the biggest power to change our life. Used in a purposeful way, even in short lifespan and limited energy levels, it has led to personal fulfilments, or human achievements that are remembered throughout millennials. Used purposelessly, can lead to wasted long life full of energy, and many regrets in a death bed. THE HAPPINESS FORMULA If time is a yes/no constant, and the energy level is a multiplier for every moment, then focus is the exponent of all. Every moment, we are alive, we have a certain energy level that we can use for something purposeful or waste for nothing. Then we have recharge again. Every moment we have the ability to focus our energy to things that matter to us, or waste it aimlessly. Life happiness is the sum of all moments we had, with sufficient energy to help us focus on things that makes us happy. Happiness is the sum of all finite moments where we focus our energy towards our purpose Every time we waste these finite resources, they're gone forever. Make sure you are alive first, healthy and energised second, and also focused on what makes you happy. These variables build on top of each other and require a delicate balance. Focus too much on one thing, and you may lose your life in an instant. Ignore your health, and your energy levels will suffer hindering the ability to focus. Do everything right, and still a meteor can hit you and end it all. There is no guarantee, or fairness in any of these, only the awareness of its working. This formula is re presentation of how these finite resources can be transformed into happiness in the equation called life.</content><dc:creator>Unknown</dc:creator></entry><entry><title>Quarkus 3.1.2.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-1-2-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-1-2-final-released/</id><updated>2023-06-16T00:00:00Z</updated><published>2023-06-16T00:00:00Z</published><summary type="html">We released Quarkus 3.1.2.Final, the second maintenance release of our 3.1 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 3.1. If you are not already using 3.1, please refer to the Quarkus 3.1 migration guide. And if you...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-06-16T00:00:00Z</dc:date></entry><entry><title>How to use Ansible to create a VM on Azure</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure" /><author><name>Deepankar Jain</name></author><id>32865531-f2b4-4927-ab77-8d80f69d9656</id><updated>2023-06-15T18:00:00Z</updated><published>2023-06-15T18:00:00Z</published><summary type="html">&lt;p&gt;In our &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli#"&gt;previous article&lt;/a&gt;, we explored how to use the Red Hat Ansible Automation Platform's CLI to create a virtual machine (VM) in Microsoft Azure. This time, we'll take things a step further and leverage the power of the Ansible Automation Platform to automate the process. The Ansible Automation Platform is a powerful tool that enables you to manage your infrastructure more efficiently, with less manual intervention.&lt;/p&gt; &lt;p&gt;Follow the series:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Part 1: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli#"&gt;How to automate VM creation on Azure with Ansible CLI&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 2: How to use Ansible to create a VM on Azure&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure-workflow"&gt;How to use Ansible to create a VM on Azure via workflow&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;By using the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt;, we can create a streamlined process for deploying VMs in Azure, reducing errors and saving time. In this article, we'll dive into the details of how to use the Ansible Automation Platform to create VMs in Azure.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;1. The operating system on your local machine must be Red Hat Enterprise Linux (&lt;a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux"&gt;RHEL&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;2. Before you can complete any of the following tasks, you must create a &lt;a href="https://access.redhat.com/terms-based-registry/"&gt;registry service account&lt;/a&gt;. To log in to service account (SA), you'll need to use a container runtime such as Podman or Docker. &lt;a href="https://podman.io/"&gt;Podman&lt;/a&gt; is a powerful and secure open-source tool that can be used as an alternative to Docker, with the added benefits of not requiring a daemon to run containers and having a more lightweight footprint. We recommend &lt;a href="https://podman.io/getting-started/installation"&gt;installing Podman&lt;/a&gt;. This &lt;a href="https://developers.redhat.com/articles/podman-next-generation-linux-container-tools"&gt;article&lt;/a&gt; explains how Podman offers a more efficient container experience.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman login registry.redhat.io Username: {REGISTRY-SERVICE-ACCOUNT-USERNAME} Password: {REGISTRY-SERVICE-ACCOUNT-PASSWORD} Login Succeeded!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once we are successful in logging into the SA, we need to create a container image by using a Dockerfile containing the following context:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;FROM registry.redhat.io/ansible-automation-platform-22/ee-supported-rhel8:latest RUN pip3 install 'ansible[azure]' RUN ansible-galaxy collection install azure.azcollection RUN pip3 install -r ~/.ansible/collections/ansible_collections/azure/azcollection/requirements-azure.txt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Build an image using Podman as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman build -t &lt;image-name&gt;.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Push the image into the container image registry. Log in to the private container image registry using the &lt;code&gt;podman login&lt;/code&gt; command before pushing.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman push &lt;image-name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;div&gt;Add the image name in the execution environment, as shown in Figure 1. You can also use the &lt;a href="https://developers.redhat.com/learning/learn%3Aansible/resource/resources%3Aget-started-ansible-automation-platform-builder"&gt;execution environment builder&lt;/a&gt; to create a custom execution environment. &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_11-58-11.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_11-58-11.png?itok=xXki-AuG" width="600" height="295" alt="A screenshot of the execution environment page of Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The execution environment page of Ansible Automation Platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;3. Create an &lt;a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal"&gt;Azure Active Directory&lt;/a&gt; (Azure AD) account, a service principal, and give permissions in Azure.&lt;/p&gt; &lt;p&gt;4. Follow these &lt;a href="https://learn.microsoft.com/en-us/azure/industry/training-services/microsoft-community-training/frequently-asked-questions/generate-new-clientsecret-link-to-key-vault"&gt;instructions&lt;/a&gt; to generate a client secret for the service principal. &lt;/p&gt; &lt;p&gt;5. Click &lt;strong&gt;Credentials&lt;/strong&gt; under &lt;strong&gt;Resources &lt;/strong&gt;and select &lt;strong&gt;Microsoft Azure Resource Manager.&lt;/strong&gt; Then, enter your subscription_id, tenant id, client id, secret, username, and password (Figure 2).&lt;/p&gt; &lt;/div&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-34-59.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-34-59.png?itok=aXDBdtnd" width="600" height="317" alt="A screenshot of the Azure credentials page in Ansible." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Enter your Azure credentials in Ansible Automation Platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating and configuring the project&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Install the Ansible Automation Platform by following these &lt;a href="https://developers.redhat.com/articles/2023/01/01/how-install-red-hat-ansible-automation-platform-rhel-9"&gt;instructions&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Log in to the Ansible Automation Platform Portal in browser.&lt;/li&gt; &lt;li aria-level="1"&gt;Navigate to the &lt;strong&gt;Projects&lt;/strong&gt; tab under &lt;strong&gt;Resources&lt;/strong&gt; in the left pane.&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Add&lt;/strong&gt; to create a new project.&lt;/li&gt; &lt;li aria-level="1"&gt;Enter a name for the project and choose &lt;strong&gt;Git&lt;/strong&gt; as the source control type with the URL: https://github.com/redhat-developer-demos/ansible-automation-platform-cloud-solutions in the &lt;strong&gt;Source Control URL&lt;/strong&gt; field. If you're interested in checking out the Ansible Playbooks, you can find them on &lt;a href="https://github.com/redhat-developer-demos/ansible-automation-platform-cloud-solutions"&gt;Github&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Save the changes and wait for the operation to complete successfully (Figure 3).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-37-05.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-37-05.png?itok=5w6HVdXy" width="600" height="129" alt="A screenshot of the source control project in Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The source control in the project in Ansible Automation Platform.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating and configuring the job template&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Go to the &lt;strong&gt;Templates&lt;/strong&gt; tab under resources in the left pane, click the &lt;strong&gt;add&lt;/strong&gt; button, and select &lt;strong&gt;Job template&lt;/strong&gt; from the options.&lt;/li&gt; &lt;li aria-level="1"&gt;Enter a name for the job you want to create, select the &lt;strong&gt;Demo-Inventory&lt;/strong&gt; or &lt;strong&gt;Default inventory&lt;/strong&gt; in the &lt;strong&gt;Inventory&lt;/strong&gt; section.&lt;/li&gt; &lt;li aria-level="1"&gt;In the &lt;strong&gt;Project&lt;/strong&gt; section, click on the project name you previously created and select the Azure/create_vm_job_template.yml file.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Configuring the variables and execution environment&lt;/h3&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Variables&lt;/strong&gt; section and add the variables as follows:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-yaml"&gt;--- vm_name: "Test-Ansible" vm_size: "Standard_B1ls" vm_image: "RedHat:RHEL:8-LVM:latest" vm_username: "testansible" vm_password: "my-password@1234" rg_name: "test-ansible" vnet_name: "test-ansible" subnet_name: "test-ansible" location: "centralindia" offer: “CentOS” publisher: “OpenLogic” sku: “7.5” version: ”latest”&lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Select the credentials you previously created under the selected category (Figure 4).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-40-15.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-40-15.png?itok=dfwqZin1" width="600" height="259" alt="A screenshot of the form for selecting pre-configured Azure credentials." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4 : Select pre-configured Azure credentials for secure authentication.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Select the execution environment you previously created (Figure 5).&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-27_09-42-54.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-27_09-42-54.png?itok=QISI_KtX" width="600" height="408" alt="Figure 4: Selecting pre-configured execution environment" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Selecting the pre-configured execution environment.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Save your changes by clicking the &lt;strong&gt;Save&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Launch&lt;/strong&gt; button to launch the job.&lt;/li&gt; &lt;li&gt;Once the job is launched using the Ansible Automation Platform, the system will generate an output, as shown in Figure 6. The output displays the job status and the progress of the VM creation process.&lt;/li&gt; &lt;/ul&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-06-15_at_12.04.09_pm.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-06-15_at_12.04.09_pm.png?itok=LWz4-Zuq" width="600" height="281" alt="A screenshot of the output from the job in the Ansible Automation Platform console." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: The output from the job in the Ansible Automation Platform console.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;You can&lt;span&gt; check the virtual machine by navigating to the Azure portal&lt;/span&gt;&lt;span&gt;.&lt;/span&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to use the Ansible Automation Platform to create a VM in Microsoft Azure. You learned how the Ansible Automation Platform can streamline the process of deploying VMs in Azure, making it more efficient and less error-prone. By using the power of automation, we can save time and free up resources to focus on other important tasks.&lt;/p&gt; &lt;p&gt;You can explore more of what the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt; has to offer by &lt;a href="https://developers.redhat.com/products/ansible/download"&gt;downloading it&lt;/a&gt;. Additionally, there are &lt;a href="https://developers.redhat.com/e-books"&gt;e-books&lt;/a&gt; such as, &lt;a href="https://developers.redhat.com/e-books/automation-at-the-edge"&gt;Automation at the edge&lt;/a&gt;, &lt;a href="https://developers.redhat.com/e-books/choosing-automation-tool"&gt;Choosing an Automation Tool&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/e-books/it-executives-guide-automation"&gt;An IT executive's guide to automation&lt;/a&gt;. A cheat sheet is also available for &lt;a href="https://developers.redhat.com/cheat-sheets/wifi-automation-ansible-and-sd-wan-meraki-cheat-sheet"&gt;WiFi automation with Ansible and SD&lt;/a&gt; that provides a quick reference for network automation tasks.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure-workflow"&gt;final article&lt;/a&gt; in this 3-part series will demonstrate how to simplify the process of creating VMs in Azure by using workflow templates. Workflow templates can help standardize the process of creating VMs and reduce the amount of manual intervention required. &lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure" title="How to use Ansible to create a VM on Azure"&gt;How to use Ansible to create a VM on Azure&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Deepankar Jain</dc:creator><dc:date>2023-06-15T18:00:00Z</dc:date></entry><entry><title>How to automate VM creation on Azure with Ansible CLI</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli" /><author><name>Deepankar Jain</name></author><id>54f40aea-f407-4a04-a9c5-da85ffe5427a</id><updated>2023-06-15T07:00:00Z</updated><published>2023-06-15T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will demonstrate how to use the Red Hat Ansible Automation Platform command-line interface (CLI) to create a virtual machine on Microsoft Azure. We will walk you through the steps required to get started with Ansible Automation Platform and Azure, including setting up the necessary resources and creating a VM using the Azure module and Ansible Automation Platform.&lt;/p&gt; &lt;p&gt;This series covers the end-to-end process of creating a Virtual Machine(VM) on Azure using Ansible Automation Platform. This 3-part series includes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Part 1: How to automate VM creation on Azure with Ansible CLI&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure"&gt;How to use Ansible to create a VM on Azure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure-workflow"&gt;How to use Ansible to create a VM on Azure via workflow&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;By the end of this article, you'll have a better understanding of how to use Ansible Automation Platform CLI to manage VMs and how this streamlines your infrastructure management workflows.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Before you begin this tutorial, complete the following:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Make sure &lt;a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html"&gt;Ansible Automation Platform&lt;/a&gt; is installed on your system.&lt;/li&gt; &lt;li aria-level="1"&gt;Create a Microsoft Azure account.&lt;/li&gt; &lt;li aria-level="1"&gt;Install &lt;a href="https://galaxy.ansible.com/azure/azcollection"&gt;Ansible content collection for Azure&lt;/a&gt; on your system.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How to use the Ansible CLI to create a VM&lt;/h2&gt; &lt;p&gt;Follow these steps to create a virtual machine using Ansible Automation Platform CLI:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal"&gt;Create a service principal and give permissions in Azure&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/industry/training-services/microsoft-community-training/frequently-asked-questions/generate-new-clientsecret-link-to-key-vault"&gt;Generate the client secret for service principal&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;You should now have a&lt;strong&gt; subscriptionid, tenantid, clientid and client secret &lt;/strong&gt;that you can use to access your Azure Account and launch a VM.&lt;/li&gt; &lt;li aria-level="1"&gt;Open any text editor on your local machine and copy the following yml into it:&lt;/li&gt; &lt;/ul&gt;&lt;pre&gt; &lt;code class="language-yaml"&gt;--- # Get facts for the user - name: Create a Virtual Machine on Azure Using Ansible hosts: localhost vars: vm_name: "Test-Ansible" vm_size: "Standard_B1ls" vm_image: "RedHat:RHEL:8-LVM:latest" vm_username: "testansible" vm_password: "my-password@1234" rg_name: "test-ansible" vnet_name: "test-ansible" subnet_name: "test-ansible" location: "centralindia" subscription_id: &lt;YOUR SUBSCRIPTION ID&gt; tenant: &lt;YOUR TENANT ID&gt; client_id: &lt;YOUR CLIENT ID&gt; secret: &lt;YOUR SECRET&gt; tasks: - name: Create a Resource Group azure.azcollection.azure_rm_resourcegroup: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" name: "{{ rg_name }}" location: "{{ location }}" register: rg - name: Create a Virtual Network azure.azcollection.azure_rm_virtualnetwork: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vnet_name }}" address_prefixes: "10.0.0.0/16" register: vnet - name: Create a subnet azure.azcollection.azure_rm_subnet: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" virtual_network_name: "{{ vnet_name }}" name: "{{ subnet_name }}" address_prefix: "10.0.0.0/24" register: subnet - name: Create a public IP address azure.azcollection.azure_rm_publicipaddress: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" allocation_method: static name: "{{ vm_name }}-public-ip" register: public_ip - name: Create a network security group and configure the security group azure.azcollection.azure_rm_securitygroup: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vm_name }}-nsg" rules: - name: "AllowSSH" protocol: Tcp direction: Inbound priority: 1000 access: Allow source_address_prefix: "*" source_port_range: "*" destination_port_range: "22" destination_address_prefix: "*" register: nsg - name: Create a Virtual Network Interface Card azure.azcollection.azure_rm_networkinterface: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vm_name }}-nic" virtual_network: "{{ vnet_name }}" subnet_name: "{{ subnet_name }}" public_ip_name: "{{ vm_name }}-public-ip" security_group: "{{ vm_name }}-nsg" - name: Create a vm_image azure.azcollection.azure_rm_virtualmachine: subscription_id: "{{ subscription_id }}" tenant: "{{ tenant }}" client_id: "{{ client_id }}" secret: "{{ secret }}" resource_group: "{{ rg_name }}" name: "{{ vm_name }}" vm_size: "{{ vm_size }}" admin_username: "{{ vm_username }}" admin_password: "{{ vm_password }}" image: offer: "CentOS" publisher: "OpenLogic" sku: "7.5" version: "latest" os_disk_caching: ReadWrite os_disk_name: "{{ vm_name }}-os-disk" network_interface_names: - "{{ vm_name }}-nic" network_interfaces: - name: "{{ vm_name }}-nic" properties: primary: True availability_set: null ssh_public_keys: [] ssh_password_enabled: true &lt;/code&gt;&lt;/pre&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Save and close the file.&lt;/li&gt; &lt;li aria-level="1"&gt;Open the terminal in the directory where the file is located on your local machine.&lt;/li&gt; &lt;li aria-level="1"&gt;Run the following command: &lt;pre&gt; &lt;code class="language-bash"&gt;ansible-playbook &lt;filename&gt;.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;ansible-playbook -i inventory azure_cli.yml PLAY [Create a Virtual Machine on Azure Using Ansible] ************************************************************************************************************************************************************ TASK [Gathering Facts] ******************************************************************************************************************************************************************************************** ok: [localhost] TASK [Create a Resource Group] ************************************************************************************************************************************************************************************ changed: [localhost] TASK [Create a Virtual Network] *********************************************************************************************************************************************************************************** changed: [localhost] TASK [Create a subnet] ******************************************************************************************************************************************************************************************** changed: [localhost] TASK [Create a public IP address] ********************************************************************************************************************************************************************************* changed: [localhost] TASK [Create a network security group and configure the security group] ******************************************************************************************************************************************* changed: [localhost] TASK [Create a Virtual Network Interface Card] ******************************************************************************************************************************************************************** [DEPRECATION WARNING]: Setting ip_configuration flatten is deprecated and will be removed. Using ip_configurations list to define the ip configuration. This feature will be removed in version [2, 9]. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. changed: [localhost] TASK [Create a vm_image] ****************************************************************************************************************************************************************************************** [WARNING]: Both option network_interface_names and its alias network_interfaces are set. changed: [localhost] PLAY RECAP ******************************************************************************************************************************************************************************************************** localhost : ok=8 changed=7 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 &lt;/code&gt;&lt;/pre&gt; Figure 1 shows the the Microsoft Azure VM. &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_from_2023-04-26_13-04-45.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_from_2023-04-26_13-04-45.png?itok=57gOPDNO" width="600" height="297" alt="A screenshot of the Microsoft Azure virtual machine." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The Microsoft Azure virtual machine.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to create a VM using &lt;a href="https://developers.redhat.com/learn/ansible"&gt;Ansible Automation Platform&lt;/a&gt;. If you followed this step-by-step guide, you should now have a good understanding of how to use Ansible Automation Platform to automate the creation of a VM.&lt;/p&gt; &lt;p&gt;In our &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-use-ansible-create-vm-azure"&gt;next article&lt;/a&gt; in this series, we will explore how &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible Automation Platform&lt;/a&gt; further eases the process of creating VMs by defining infrastructure as code, tracking infrastructure changes, and enforcing compliance policies.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Get started&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; with Ansible Automation Platform by exploring interactive hands-on labs. &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://developers.redhat.com/products/ansible/download"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;Download Ansible Automation Platform&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; at no cost and begin your automation journey. You can refer to &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href="https://developers.redhat.com/e-books/choosing-automation-tool"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;An IT executive's guide to automation&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; e-book for a better understanding of the Ansible Automation Platform.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/15/how-automate-vm-creation-azure-ansible-cli" title="How to automate VM creation on Azure with Ansible CLI"&gt;How to automate VM creation on Azure with Ansible CLI&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Deepankar Jain</dc:creator><dc:date>2023-06-15T07:00:00Z</dc:date></entry><entry><title type="html">Java 21 Unnamed Classes and Instance Main Methods</title><link rel="alternate" href="https://www.mastertheboss.com/java/java-21-unnamed-classes-and-instance-main-methods/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/java/java-21-unnamed-classes-and-instance-main-methods/</id><updated>2023-06-13T10:38:54Z</updated><content type="html">Java 21 introduces two language core features: Unnamed Java Classes and a new launch protocol which allows running Java classes in a simpler format. In this article we will cover in detail these new features explaining how they can simplify your daily Java coding. Java 21 introduces two core features that will simplify the coding ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Improvements to Native Image JFR support in GraalVM for JDK 20</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/06/13/improvements-native-image-jfr-support-graalvm-jdk-20" /><author><name>Robert Toyonaga</name></author><id>cadfd7a6-afc0-41dd-af7f-cd88a02ab360</id><updated>2023-06-13T07:00:00Z</updated><published>2023-06-13T07:00:00Z</published><summary type="html">&lt;p&gt;This article describes the improvements to the Native Image JFR support in GraalVM JDK 20. This is a follow up to a previous article's section, &lt;a href="https://developers.redhat.com/articles/2021/07/23/jdk-flight-recorder-support-graalvm-native-image-journey-so-far#implementing_jdk_flight_recorder_support_for_graalvm_native_image"&gt;Implementing JDK Flight Recorder support for GraalVM Native Image&lt;/a&gt;. JDK Flight Recorder (JFR) is a powerful tool that assists the profiling, debugging, and monitoring of &lt;a href="https://developers.redhat.com/java"&gt;Java&lt;/a&gt; applications. We will discuss the new developments available in GraalVM for JDK 17 and JDK 20.&lt;/p&gt; &lt;h2&gt;3 steps to build a native image with JFR&lt;/h2&gt; &lt;p&gt;These steps illustrate the simplest way to use JFR with Native Image. You can also start a JFR recording over a JMX connection as described in the sections that follow, or by using the &lt;code&gt;jdk.jfr.Recording&lt;/code&gt; API from within your application code.&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Compile your application to byte code as follows: &lt;pre&gt; &lt;code class="language-bash"&gt;$JAVA_HOME/bin/javac YourApplication.java&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Use the &lt;code&gt;--enable-monitoring &lt;/code&gt;option to build a native image with JFR support: &lt;pre&gt; &lt;code class="language-bash"&gt;native-image --enable-monitoring=jfr YourApplication&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Run with Flight Recorder. &lt;pre&gt; &lt;code&gt;./yourapplication -XX:StartFlightRecording=duration=60s,filename=recording.jfr&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;New supported features&lt;/h2&gt; &lt;p&gt;This section will provide a brief rundown of the new major JFR features available in Native Image.&lt;/p&gt; &lt;h3&gt;Stack traces&lt;/h3&gt; &lt;p&gt;The first big improvement to JFR in Native Image is support for event stack traces. This also allows for method profiling which can provide insight into where your application is spending the most time, as shown in Figure 1. Events now carry stack traces so you can easily see where they are getting emitted. &lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/method_profiling_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/method_profiling_0.png?itok=PJQBDiyJ" width="600" height="420" alt="Method Profiling page in JMC shown with flame graph." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Remote JMX connection&lt;/h3&gt; &lt;p&gt;Remote connection via JMX is also possible, the &lt;code&gt;jdk.management.jfr.FlightRecorderMXBean&lt;/code&gt;. This means that JFR recordings can be started remotely from out of process (from either another JVM or native image). Unfortunately, the Flight Recorder wizard in JMC does not recognize non-hotspot JVMs, which means you must interact with FlightRecorderMXBean from the &lt;strong&gt;MBean Browser&lt;/strong&gt; tab, as shown in Figure 2.&lt;/p&gt; &lt;p&gt;Remote JMX support in Native Image is still experimental, so you can expect more changes in this area in the future. Currently, PlatformMXBeans (i.e., ThreadMXBean) are only partially supported because the underlying implementations in SubstrateVM do not exist yet. The amount of reflection, dynamic proxy, and serialization metadata configuration required to support remote JMX is large because it is unknown ahead of time what MBeans and operations will be used. This means that JMX support results in an image size increase of a little over 20 MB. Please see the &lt;a href="https://www.graalvm.org/dev/reference-manual/native-image/guides/build-and-run-native-executable-with-remote-jmx/"&gt;GraalVM website&lt;/a&gt; for more information on remote JMX and its limitations.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/flightrecordermxbean.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/flightrecordermxbean.png?itok=CqTQiPkk" width="600" height="271" alt="The FlightRecorderMXBean operations in JMC." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2. FlightRecorderMXBean operations in JMC.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;How to create a JFR Recording using JMC over JMX&lt;/h4&gt; &lt;p&gt;1. Build your native image with: &lt;code&gt;--enable-monitoring=all or --enable-monitoring=jvmstat,jfr,jmxclient,jmxserver&lt;/code&gt;&lt;/p&gt; &lt;pre&gt; &lt;code&gt;native-image --enable-monitoring=all -m jdk.httpserver&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;jvmstat&lt;/code&gt; option makes your application discoverable. The &lt;code&gt;jfr&lt;/code&gt; option adds JDK Flight Recorder Support. The &lt;code&gt;jmxclient&lt;/code&gt;/&lt;code&gt;jmxserver&lt;/code&gt; options add support for outgoing/incoming JMX connections.&lt;/p&gt; &lt;p&gt;2. Start your native image executable with JMX options. Disclaimer: these options disable SSL and password authentication (both of which are supported, but aren’t included here for convenience of the demo).&lt;/p&gt; &lt;pre&gt; &lt;code&gt;./jdk.httpserver -Dcom.sun.management.jmxremote.authenticate=false \ -Djava.rmi.server.hostname=localhost \ -Dcom.sun.management.jmxremote.port=9996 \ -Dcom.sun.management.jmxremote.ssl=false \ -Dcom.sun.management.jmxremote.local.only=false &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;3. Open JMC and select your application in the JVM browser (there's no JVM but it'll show up there because you built with jvmstat).&lt;/p&gt; &lt;p&gt;4. Navigate to the &lt;strong&gt;MBean Browser&lt;/strong&gt; tab and select &lt;strong&gt;FlightRecorderMXBean&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;5. Select the &lt;strong&gt;Operations&lt;/strong&gt; tab and execute the &lt;strong&gt;newRecording&lt;/strong&gt; operation. Make note of the returned recording ID.&lt;/p&gt; &lt;p&gt;6. Execute &lt;strong&gt;setPredefinedConfiguration&lt;/strong&gt; operation, providing the recording ID from the previous step as well as &lt;strong&gt;profile&lt;/strong&gt; as the second argument.&lt;/p&gt; &lt;p&gt;7. Execute the &lt;strong&gt;startRecording&lt;/strong&gt; operation, providing the recording ID from the previous step.&lt;/p&gt; &lt;p&gt;8. When you're ready to dump the recording, execute the &lt;strong&gt;copyTo&lt;/strong&gt; operation, providing the recording ID as well as a filename (&lt;code&gt;MyRecording.jfr&lt;/code&gt;).&lt;/p&gt; &lt;h3&gt;Event streaming&lt;/h3&gt; &lt;p&gt;Now event streaming has experimental support in Native Image. JFR event streaming was introduced in OpenJDK 14 and allows for streaming of events from an ongoing recording. Previously, recording had to be dumped to a JFR snapshot before the event data could be read. However, now an application can subscribe to a stream of its own event data (or even that of another process) and register callbacks triggered by specific events. A current limitation of event streaming in Native Image is that stack traces are not available for streamed events. This is actively being worked on and does not affect stack traces available in a snapshot file.&lt;/p&gt; &lt;h2&gt;New supported events&lt;/h2&gt; &lt;p&gt;This section highlights the new support for events grouped by category.&lt;/p&gt; &lt;h3&gt;Monitor and thread events&lt;/h3&gt; &lt;p&gt;There is now support for monitor and thread-related events. These events can provide insight into where and why threads are often stopped or waiting.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;jdk.ThreadSleep&lt;/li&gt; &lt;li&gt;jdk.ThreadPark&lt;/li&gt; &lt;li&gt;jdk.JavaMonitorEnter&lt;/li&gt; &lt;li&gt;jdk.JavaMonitorWait&lt;/li&gt; &lt;li&gt;jdkJavaMonitorInflate&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Figure 3 shows how these new events can be used in combination with newly supported stack traces to generate flame graphs identifying where threads are blocked.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blockedMonitor.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blockedMonitor.png?itok=TLVsIXRA" width="600" height="325" alt="In Native Image JFR, a flame graph showing blocking on monitors." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Allocation events&lt;/h3&gt; &lt;p&gt;The following allocation event is now supported. This event is useful for discerning the places where your application does most of its allocations. Since this event generates a lot of data/overhead, it is disabled by default (similar to OpenJDK). You can use it by providing a custom settings file with the event set to &lt;strong&gt;enabled&lt;/strong&gt; (&lt;code&gt;-XX:StartFlightRecording=settings=/path/to/settings.jfc&lt;/code&gt;).&lt;/p&gt; &lt;ul&gt;&lt;li&gt;jdk.ObjectAllocationInNewTLAB&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Container events&lt;/h3&gt; &lt;p&gt;The following events related to containers are now supported:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;jdk.ContainerCPUThrottling&lt;/li&gt; &lt;li&gt;jdk.ContainerCPUUsage&lt;/li&gt; &lt;li&gt;jdk.ContainerConfiguration&lt;/li&gt; &lt;li&gt;jdk.ContainerIOUsage&lt;/li&gt; &lt;li&gt;jdk.ContainerMemoryUsage&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What's next?&lt;/h2&gt; &lt;p&gt;Support for leak detection via the &lt;code&gt;jdk.OldObjectSample&lt;/code&gt; event is in progress. This is a sampling based approach that tracks large long-lived objects to provide insights into potential memory leaks. Support for allocation profiling is also in development via the &lt;code&gt;jdk.ObjectAllocation&lt;/code&gt; event and emission throttling. Throttling is important to control the overhead associated with instrumenting object allocations. Support for other built-in events available in OpenJDK/Hotspot continues.&lt;/p&gt; &lt;p&gt;Other features such as in memory chunk rotation are not yet being worked on. Other features are unsupported because they are not applicable to Native Image. Specifically, events related to compilation, dynamic bytecode instrumentation, and class loading are not applicable. Control of JFR via jcmd is also not possible because jcmd is unsupported in Native Image.&lt;/p&gt; &lt;p&gt;Please visit &lt;a href="https://github.com/oracle/graal/issues/5410"&gt;this GitHub issue&lt;/a&gt; for the most up-to-date list of supported JFR events in Native Image. In addition to these built-in events, the JFR custom events API is also supported. Users can create and emit their own custom application level events by extending &lt;code&gt;jdk.jfr.Event&lt;/code&gt; class.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/06/13/improvements-native-image-jfr-support-graalvm-jdk-20" title="Improvements to Native Image JFR support in GraalVM for JDK 20"&gt;Improvements to Native Image JFR support in GraalVM for JDK 20&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Robert Toyonaga</dc:creator><dc:date>2023-06-13T07:00:00Z</dc:date></entry><entry><title>Quarkus Newsletter #33 - June</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-newsletter-33/&#xA;            " /><author><name>James Cobb (https://twitter.com/insectengine)</name></author><id>https://quarkus.io/blog/quarkus-newsletter-33/</id><updated>2023-06-13T00:00:00Z</updated><published>2023-06-13T00:00:00Z</published><summary type="html">Check out the June Newsletter. Read "A Guide to the Quarkus 3 Azure Functions Extension: Bootstrap Java Microservices with Ease" by Daniel Oh &amp; Erik Costlow and to learn how Quarkus integrates Java microservices into Azure Functions with an improved developer experience. Check out "Quarkus: Java revisited!" by Willem Meints...</summary><dc:creator>James Cobb (https://twitter.com/insectengine)</dc:creator><dc:date>2023-06-13T00:00:00Z</dc:date></entry><entry><title type="html">Getting Started with Testcontainers for Java</title><link rel="alternate" href="https://www.mastertheboss.com/various-stuff/testing-java/getting-started-with-testcontainers-for-java/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/various-stuff/testing-java/getting-started-with-testcontainers-for-java/</id><updated>2023-06-12T15:04:48Z</updated><content type="html">Introduction In modern software development, it is crucial to write robust and reliable tests to ensure the quality of your applications. One essential aspect of testing is dealing with dependencies, such as databases or external services. Testcontainers is an excellent Java library that provides lightweight, disposable containers for running dependencies during tests. In this tutorial, ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">gRPC and WildFly - Part II: Exposing Jakarta RESTFul Web Services to gRPC</title><link rel="alternate" href="https://resteasy.dev/2023/06/11/grpc-in-wildfly-pt2/" /><author><name /></author><id>https://resteasy.dev/2023/06/11/grpc-in-wildfly-pt2/</id><updated>2023-06-11T00:00:00Z</updated><dc:creator /></entry></feed>
